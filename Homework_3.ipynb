{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76365a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484887"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Импортируйте библиотеки pandas и numpy.\n",
    "    Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из \n",
    "    этих данных.\n",
    "    Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции \n",
    "    train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен \n",
    "    быть равен 42.\n",
    "    Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "    Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "    Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "boston = load_boston()\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "feature_names = boston.feature_names\n",
    "X = pd.DataFrame(data, columns=feature_names)\n",
    "y = pd.DataFrame(target, columns = ['price'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa84a726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87472606157312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "    Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "    Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, но при этом в метод \n",
    "    fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy,\n",
    "    так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо \n",
    "    датафрейма.\n",
    "    Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "    Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)\n",
    "model.fit(X_train, y_train.values[:, 0])\n",
    "y_pred_2 = model.predict(X_test)\n",
    "R2_ = r2_score(y_test, y_pred_2)\n",
    "R2_\n",
    "\n",
    "# В данном случае модель, созданная с помощью RandomForestRegressor, работает лучше, чем модель, созданная с помощью LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c356f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Показатели важности: {'CRIM': 0.03167574073875602, 'ZN': 0.0015425166262328857, 'INDUS': 0.007138131415845557, 'CHAS': 0.0012362448947738866, 'NOX': 0.0142689698753483, 'RM': 0.4026817857034993, 'AGE': 0.014298644996729816, 'DIS': 0.06397256527230023, 'RAD': 0.00528121831288784, 'TAX': 0.011524934553144586, 'PTRATIO': 0.018081076405025417, 'B': 0.012450853014007697, 'LSTAT': 0.4158473181914483}\n",
      "Сумма всех показателей важности: 1.0\n",
      "Признаки с наибольшей важностью: ['LSTAT', 'RM']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Вызовите документацию для класса RandomForestRegressor, найдите информацию об атрибуте feature_importances_.\n",
    "    С помощью этого атрибута найдите сумму всех показателей важности, установите, какие два признака показывают \n",
    "    наибольшую важность.\n",
    "\"\"\"\n",
    "importances = model.feature_importances_\n",
    "importances_sum = sum(importances)\n",
    "importances_dict = {a:b for a, b in zip(feature_names, importances)}\n",
    "print(f\"Показатели важности: {importances_dict}\\nСумма всех показателей важности: {importances_sum}\\nПризнаки с наибольшей важностью:\", sorted(importances_dict, key=importances_dict.get, reverse=True)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "297f457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0        0.998273\n",
      "1        0.001727\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "None\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
      "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
      "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
      "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
      "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
      "\n",
      "         V8        V9       V10       V11       V12       V13       V14  \\\n",
      "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
      "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
      "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
      "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
      "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
      "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
      "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
      "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
      "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
      "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
      "\n",
      "        V15       V16       V17       V18       V19       V20       V21  \\\n",
      "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
      "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
      "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
      "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
      "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
      "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
      "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
      "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
      "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
      "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
      "\n",
      "        V22       V23       V24       V25       V26       V27       V28  \\\n",
      "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
      "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
      "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
      "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
      "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
      "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
      "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
      "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
      "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
      "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
      "\n",
      "   Amount  Class  \n",
      "0  149.62      0  \n",
      "1    2.69      0  \n",
      "2  378.66      0  \n",
      "3  123.50      0  \n",
      "4   69.99      0  \n",
      "5    3.67      0  \n",
      "6    4.99      0  \n",
      "7   40.80      0  \n",
      "8   93.20      0  \n",
      "9    3.68      0  \n",
      "X_train.shape:(199364, 30), X_test.shape:(85443, 30), y_train.shape:(199364,), y_test.shape:(85443,)\n",
      "Параметры лучшей модели: {'max_depth': 6, 'max_features': 3, 'n_estimators': 15}\n",
      "Значение AUC для тестовых данных:\n",
      "0.9462664156037156\n",
      "Для тренировочных данных:\n",
      "0.9703527882554751\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "    Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "    С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована. \n",
    "    Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков. Примените следующую \n",
    "    настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "    pd.options.display.max_columns = 100.\n",
    "    Просмотрите первые 10 строк датафрейма df.\n",
    "    Создайте датафрейм X из датафрейма df, исключив столбец Class. Создайте объект Series под названием y из столбца Class.\n",
    "    Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: \n",
    "    test_size=0.3, random_state=100, stratify=y.\n",
    "    У вас должны получиться объекты X_train, X_test, y_train и y_test. Просмотрите информацию о их форме.\n",
    "    Для поиска по сетке параметров задайте такие параметры:\n",
    "    parameters = [{'n_estimators': [10, 15],\n",
    "    'max_features': np.arange(3, 5),\n",
    "    'max_depth': np.arange(4, 7)}]\n",
    "    Создайте модель GridSearchCV со следующими аргументами:\n",
    "    estimator=RandomForestClassifier(random_state=100),\n",
    "    param_grid=parameters,\n",
    "    scoring='roc_auc',\n",
    "    cv=3.\n",
    "    Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "    Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "    Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "    Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив \n",
    "    y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "    Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве \n",
    "    аргументов массивы y_test и y_pred_proba.\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "print(df.value_counts([\"Class\"],normalize=True))\n",
    "print(df.info())\n",
    "pd.options.display.max_columns = 100\n",
    "print(df.head(10))\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "print(f\"X_train.shape:{X_train.shape}, X_test.shape:{X_test.shape}, y_train.shape:{y_train.shape}, y_test.shape:{y_test.shape}\")\n",
    "parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(random_state=100), param_grid=parameters, scoring='roc_auc', cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Параметры лучшей модели:\", clf.best_params_)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_train = clf.predict_proba(X_train)\n",
    "y_pred_proba = y_pred_proba[:, 1]\n",
    "y_pred_train = y_pred_train[:, 1]\n",
    "auc_test = roc_auc_score(y_test, y_pred_proba)\n",
    "auc_test_train = roc_auc_score(y_train, y_pred_train)\n",
    "print(f\"Значение AUC для тестовых данных:\\n{auc_test}\\nДля тренировочных данных:\\n{auc_test_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b3816409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Переменная содержит 3 класса - [0 1 2]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 18.2 KB\n",
      "None\n",
      "Матрица корреляций для всех полей:\n",
      "                                alcohol  malic_acid       ash  \\\n",
      "alcohol                       1.000000    0.094397  0.211545   \n",
      "malic_acid                    0.094397    1.000000  0.164045   \n",
      "ash                           0.211545    0.164045  1.000000   \n",
      "alcalinity_of_ash            -0.310235    0.288500  0.443367   \n",
      "magnesium                     0.270798   -0.054575  0.286587   \n",
      "total_phenols                 0.289101   -0.335167  0.128980   \n",
      "flavanoids                    0.236815   -0.411007  0.115077   \n",
      "nonflavanoid_phenols         -0.155929    0.292977  0.186230   \n",
      "proanthocyanins               0.136698   -0.220746  0.009652   \n",
      "color_intensity               0.546364    0.248985  0.258887   \n",
      "hue                          -0.071747   -0.561296 -0.074667   \n",
      "od280/od315_of_diluted_wines  0.072343   -0.368710  0.003911   \n",
      "proline                       0.643720   -0.192011  0.223626   \n",
      "target                       -0.328222    0.437776 -0.049643   \n",
      "\n",
      "                              alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "alcohol                               -0.310235   0.270798       0.289101   \n",
      "malic_acid                             0.288500  -0.054575      -0.335167   \n",
      "ash                                    0.443367   0.286587       0.128980   \n",
      "alcalinity_of_ash                      1.000000  -0.083333      -0.321113   \n",
      "magnesium                             -0.083333   1.000000       0.214401   \n",
      "total_phenols                         -0.321113   0.214401       1.000000   \n",
      "flavanoids                            -0.351370   0.195784       0.864564   \n",
      "nonflavanoid_phenols                   0.361922  -0.256294      -0.449935   \n",
      "proanthocyanins                       -0.197327   0.236441       0.612413   \n",
      "color_intensity                        0.018732   0.199950      -0.055136   \n",
      "hue                                   -0.273955   0.055398       0.433681   \n",
      "od280/od315_of_diluted_wines          -0.276769   0.066004       0.699949   \n",
      "proline                               -0.440597   0.393351       0.498115   \n",
      "target                                 0.517859  -0.209179      -0.719163   \n",
      "\n",
      "                              flavanoids  nonflavanoid_phenols  \\\n",
      "alcohol                         0.236815             -0.155929   \n",
      "malic_acid                     -0.411007              0.292977   \n",
      "ash                             0.115077              0.186230   \n",
      "alcalinity_of_ash              -0.351370              0.361922   \n",
      "magnesium                       0.195784             -0.256294   \n",
      "total_phenols                   0.864564             -0.449935   \n",
      "flavanoids                      1.000000             -0.537900   \n",
      "nonflavanoid_phenols           -0.537900              1.000000   \n",
      "proanthocyanins                 0.652692             -0.365845   \n",
      "color_intensity                -0.172379              0.139057   \n",
      "hue                             0.543479             -0.262640   \n",
      "od280/od315_of_diluted_wines    0.787194             -0.503270   \n",
      "proline                         0.494193             -0.311385   \n",
      "target                         -0.847498              0.489109   \n",
      "\n",
      "                              proanthocyanins  color_intensity       hue  \\\n",
      "alcohol                              0.136698         0.546364 -0.071747   \n",
      "malic_acid                          -0.220746         0.248985 -0.561296   \n",
      "ash                                  0.009652         0.258887 -0.074667   \n",
      "alcalinity_of_ash                   -0.197327         0.018732 -0.273955   \n",
      "magnesium                            0.236441         0.199950  0.055398   \n",
      "total_phenols                        0.612413        -0.055136  0.433681   \n",
      "flavanoids                           0.652692        -0.172379  0.543479   \n",
      "nonflavanoid_phenols                -0.365845         0.139057 -0.262640   \n",
      "proanthocyanins                      1.000000        -0.025250  0.295544   \n",
      "color_intensity                     -0.025250         1.000000 -0.521813   \n",
      "hue                                  0.295544        -0.521813  1.000000   \n",
      "od280/od315_of_diluted_wines         0.519067        -0.428815  0.565468   \n",
      "proline                              0.330417         0.316100  0.236183   \n",
      "target                              -0.499130         0.265668 -0.617369   \n",
      "\n",
      "                              od280/od315_of_diluted_wines   proline    target  \n",
      "alcohol                                           0.072343  0.643720 -0.328222  \n",
      "malic_acid                                       -0.368710 -0.192011  0.437776  \n",
      "ash                                               0.003911  0.223626 -0.049643  \n",
      "alcalinity_of_ash                                -0.276769 -0.440597  0.517859  \n",
      "magnesium                                         0.066004  0.393351 -0.209179  \n",
      "total_phenols                                     0.699949  0.498115 -0.719163  \n",
      "flavanoids                                        0.787194  0.494193 -0.847498  \n",
      "nonflavanoid_phenols                             -0.503270 -0.311385  0.489109  \n",
      "proanthocyanins                                   0.519067  0.330417 -0.499130  \n",
      "color_intensity                                  -0.428815  0.316100  0.265668  \n",
      "hue                                               0.565468  0.236183 -0.617369  \n",
      "od280/od315_of_diluted_wines                      1.000000  0.312761 -0.788230  \n",
      "proline                                           0.312761  1.000000 -0.633717  \n",
      "target                                           -0.788230 -0.633717  1.000000  \n",
      "Признаки, корреляция которых с полем target по абсолютному значению превышает 0.5:\n",
      " Index(['alcalinity_of_ash', 'total_phenols', 'flavanoids', 'hue',\n",
      "       'od280/od315_of_diluted_wines', 'proline'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>alcalinity_of_ash_2</th>\n",
       "      <th>total_phenols_2</th>\n",
       "      <th>flavanoids_2</th>\n",
       "      <th>hue_2</th>\n",
       "      <th>od280/od315_of_diluted_wines_2</th>\n",
       "      <th>proline_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>243.36</td>\n",
       "      <td>7.8400</td>\n",
       "      <td>9.3636</td>\n",
       "      <td>1.0816</td>\n",
       "      <td>15.3664</td>\n",
       "      <td>1134225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>125.44</td>\n",
       "      <td>7.0225</td>\n",
       "      <td>7.6176</td>\n",
       "      <td>1.1025</td>\n",
       "      <td>11.5600</td>\n",
       "      <td>1102500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>345.96</td>\n",
       "      <td>7.8400</td>\n",
       "      <td>10.4976</td>\n",
       "      <td>1.0609</td>\n",
       "      <td>10.0489</td>\n",
       "      <td>1404225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>282.24</td>\n",
       "      <td>14.8225</td>\n",
       "      <td>12.1801</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>11.9025</td>\n",
       "      <td>2190400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>441.00</td>\n",
       "      <td>7.8400</td>\n",
       "      <td>7.2361</td>\n",
       "      <td>1.0816</td>\n",
       "      <td>8.5849</td>\n",
       "      <td>540225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>420.25</td>\n",
       "      <td>2.8224</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>3.0276</td>\n",
       "      <td>547600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>529.00</td>\n",
       "      <td>3.2400</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>2.4336</td>\n",
       "      <td>562500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>400.00</td>\n",
       "      <td>2.5281</td>\n",
       "      <td>0.4761</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>2.4336</td>\n",
       "      <td>697225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>400.00</td>\n",
       "      <td>2.7225</td>\n",
       "      <td>0.4624</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>2.6244</td>\n",
       "      <td>705600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>600.25</td>\n",
       "      <td>4.2025</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>2.5600</td>\n",
       "      <td>313600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  alcalinity_of_ash_2  \\\n",
       "0                            3.92   1065.0               243.36   \n",
       "1                            3.40   1050.0               125.44   \n",
       "2                            3.17   1185.0               345.96   \n",
       "3                            3.45   1480.0               282.24   \n",
       "4                            2.93    735.0               441.00   \n",
       "..                            ...      ...                  ...   \n",
       "173                          1.74    740.0               420.25   \n",
       "174                          1.56    750.0               529.00   \n",
       "175                          1.56    835.0               400.00   \n",
       "176                          1.62    840.0               400.00   \n",
       "177                          1.60    560.0               600.25   \n",
       "\n",
       "     total_phenols_2  flavanoids_2   hue_2  od280/od315_of_diluted_wines_2  \\\n",
       "0             7.8400        9.3636  1.0816                         15.3664   \n",
       "1             7.0225        7.6176  1.1025                         11.5600   \n",
       "2             7.8400       10.4976  1.0609                         10.0489   \n",
       "3            14.8225       12.1801  0.7396                         11.9025   \n",
       "4             7.8400        7.2361  1.0816                          8.5849   \n",
       "..               ...           ...     ...                             ...   \n",
       "173           2.8224        0.3721  0.4096                          3.0276   \n",
       "174           3.2400        0.5625  0.4900                          2.4336   \n",
       "175           2.5281        0.4761  0.3481                          2.4336   \n",
       "176           2.7225        0.4624  0.3600                          2.6244   \n",
       "177           4.2025        0.5776  0.3721                          2.5600   \n",
       "\n",
       "     proline_2  \n",
       "0    1134225.0  \n",
       "1    1102500.0  \n",
       "2    1404225.0  \n",
       "3    2190400.0  \n",
       "4     540225.0  \n",
       "..         ...  \n",
       "173   547600.0  \n",
       "174   562500.0  \n",
       "175   697225.0  \n",
       "176   705600.0  \n",
       "177   313600.0  \n",
       "\n",
       "[178 rows x 19 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 1). Загрузите датасет Wine из встроенных датасетов sklearn.datasets с помощью функции load_wine в переменную data.\n",
    "    2). Полученный датасет не является датафреймом. Это структура данных, имеющая ключи аналогично словарю. Просмотрите \n",
    "    тип данных этой структуры данных и создайте список data_keys, содержащий ее ключи.\n",
    "    3). Просмотрите данные, описание и названия признаков в датасете. Описание нужно вывести в виде привычного, аккуратно \n",
    "    оформленного текста, без обозначений переноса строки, но с самими переносами и т.д.4). Сколько классов содержит целевая \n",
    "    переменная датасета? Выведите названия классов.\n",
    "    5). На основе данных датасета (они содержатся в двумерном массиве Numpy) и названий признаков создайте датафрейм под \n",
    "    названием X.\n",
    "    6). Выясните размер датафрейма X и установите, имеются ли в нем пропущенные значения.\n",
    "    7). Добавьте в датафрейм поле с классами вин в виде чисел, имеющих тип данных numpy.int64. Название поля - 'target'.\n",
    "    8). Постройте матрицу корреляций для всех полей X. Дайте полученному датафрейму название X_corr.\n",
    "    9). Создайте список high_corr из признаков, корреляция которых с полем target по абсолютному значению превышает 0.5 \n",
    "    (причем, само поле target не должно входить в этот список).\n",
    "    10). Удалите из датафрейма X поле с целевой переменной. Для всех признаков, названия которых содержатся в списке \n",
    "    high_corr, вычислите квадрат их значений и добавьте в датафрейм X соответствующие поля с суффиксом '_2', добавленного \n",
    "    к первоначальному названию признака. Итоговый датафрейм должен содержать все поля, которые, были в нем изначально, а \n",
    "    также поля с признаками из списка high_corr, возведенными в квадрат. Выведите описание полей датафрейма X с помощью \n",
    "    метода describe.\n",
    "\"\"\"\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data = load_wine()\n",
    "print(type(data))\n",
    "data_keys = data.keys()\n",
    "pd.options.display.max_columns = 100\n",
    "print(data_keys)\n",
    "print(data.data)\n",
    "print(data.DESCR)\n",
    "print(data.feature_names)\n",
    "print(f\"Переменная содержит {len(np.unique(data.target))} класса - {np.unique(data.target)}\\n\")\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "print(X.info())\n",
    "X['target'] = data.target.astype(np.int64)\n",
    "X_corr = X.corr()\n",
    "print(\"Матрица корреляций для всех полей:\\n\", X_corr)\n",
    "high_corr = X_corr.loc[(abs(X_corr['target']) > 0.5) & (abs(X_corr['target']) != 1.0)]\n",
    "high_corr = high_corr['target'].index\n",
    "print(\"Признаки, корреляция которых с полем target по абсолютному значению превышает 0.5:\\n\", high_corr)\n",
    "X = X.drop('target', axis=1)\n",
    "for el in high_corr:\n",
    "    X[el + \"_2\"] = X[el] ** 2\n",
    "X.describe()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1a445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
